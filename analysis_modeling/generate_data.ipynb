{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21507f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "import numpy as np\n",
    "import random\n",
    "from andi_datasets.models_phenom import models_phenom\n",
    "from andi_datasets.datasets_phenom import datasets_phenom\n",
    "from andi_datasets.utils_challenge import label_continuous_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "T = 200\n",
    "L = None\n",
    "\n",
    "WINDOW_WIDTHS = np.arange(10, 100, 2)\n",
    "SHIFT_WIDTH = 40\n",
    "REG_JUMP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f88640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncumulate(xs:np.ndarray):\n",
    "    assert xs.ndim == 1\n",
    "    uncum_list = [0.]\n",
    "    for i in range(1, len(xs)):\n",
    "        uncum_list.append(xs[i] - xs[i-1])\n",
    "    return np.array(uncum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(x_pos, y_pos, win_widths):\n",
    "    all_vals = []\n",
    "    for win_width in win_widths:\n",
    "        if win_width >= len(x_pos):\n",
    "            continue\n",
    "        vals = []\n",
    "        for checkpoint in range(int(win_width/2), len(x_pos) - int(win_width/2)):\n",
    "            xs = x_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "            ys = y_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "\n",
    "            xs1 = xs[:int(len(xs)/2)] - float(xs[:int(len(xs)/2)][0])\n",
    "            xs2 = xs[int(len(xs)/2):] - float(xs[int(len(xs)/2):][0])\n",
    "\n",
    "            ys1 = ys[:int(len(ys)/2)] - float(ys[:int(len(ys)/2)][0])\n",
    "            ys2 = ys[int(len(ys)/2):] - float(ys[int(len(ys)/2):][0])\n",
    "\n",
    "            std_xs1 = np.std(xs1)\n",
    "            std_xs2 = np.std(xs2)\n",
    "            std_ys1 = np.std(ys1)\n",
    "            std_ys2 = np.std(ys2)\n",
    "\n",
    "            surface_xs1 = abs(np.sum(xs1)) / win_width\n",
    "            surface_xs2 = abs(np.sum(xs2)) / win_width\n",
    "            surface_ys1 = abs(np.sum(ys1)) / win_width\n",
    "            surface_ys2 = abs(np.sum(ys2)) / win_width\n",
    "\n",
    "\n",
    "            xs1 = np.cumsum(abs(xs1)) #* surface_xs1\n",
    "            xs2 = np.cumsum(abs(xs2)) #* surface_xs2\n",
    "            ys1 = np.cumsum(abs(ys1)) #* surface_ys1\n",
    "            ys2 = np.cumsum(abs(ys2)) #* surface_ys2\n",
    "\n",
    "\n",
    "            xs_max_val = max(np.max(abs(xs1)), np.max(abs(xs2)))\n",
    "            xs1 = xs1 / xs_max_val\n",
    "            xs2 = xs2 / xs_max_val\n",
    "            xs1 = xs1 / win_width\n",
    "            xs2 = xs2 / win_width\n",
    "\n",
    "            ys_max_val = max(np.max(abs(ys1)), np.max(abs(ys2)))\n",
    "            ys1 = ys1 / ys_max_val\n",
    "            ys2 = ys2 / ys_max_val\n",
    "            ys1 = ys1 / win_width \n",
    "            ys2 = ys2 / win_width\n",
    "\n",
    "            vals.append(abs(np.sum(xs1 - xs2 + ys1 - ys2)) \n",
    "                       * (max(std_xs1, std_xs2) / min(std_xs1, std_xs2)) \n",
    "                             * (max(std_ys1, std_ys2) / min(std_ys1, std_ys2)))\n",
    "\n",
    "        vals = np.concatenate((np.ones(int(win_width/2)) * -1, vals))\n",
    "        vals = np.concatenate((vals, np.ones(int(win_width/2)) * -1))\n",
    "        vals = np.array(vals)\n",
    "        all_vals.append(vals)\n",
    "    \n",
    "    all_vals = np.array(all_vals) + 1e-7\n",
    "    normalized_vals = all_vals.copy()\n",
    "    for i in range(len(normalized_vals)):\n",
    "            normalized_vals[i] = normalized_vals[i] / np.max(normalized_vals[i])\n",
    "    return all_vals, normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa65e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_signals(signals):\n",
    "    compressed_signal = []\n",
    "    nb_signal = signals.shape[1]\n",
    "    \n",
    "    for row in signals.transpose():\n",
    "        nb_activ_window = np.sum(row >= 0)\n",
    "        if nb_activ_window != 0:\n",
    "            comp = np.sum(row[row >= 0])\n",
    "        else:\n",
    "            comp = 1e-7\n",
    "        compressed_signal.append(comp)\n",
    "    compressed_signal = (np.array(compressed_signal) - float(np.min(compressed_signal))) / np.max(compressed_signal)\n",
    "    return compressed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847a01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_with_shift(signal, feat1, feat2, changepoints=None, count_0=None, count_1=None):\n",
    "    chopped_signals = []\n",
    "    chopped_labels = []\n",
    "    reg_chopped_signals = []\n",
    "    reg_chopped_labels = []\n",
    "    pat=0\n",
    "\n",
    "    changepoints_reg = []\n",
    "    for cp in changepoints:\n",
    "        changepoints_reg.extend(range(cp - SHIFT_WIDTH//4, cp + SHIFT_WIDTH//4))\n",
    "    changepoints_reg = set(changepoints_reg)\n",
    "        \n",
    "    if len(changepoints) != 0:\n",
    "        for cp in changepoints:\n",
    "            if cp >= (SHIFT_WIDTH//2) and cp < signal.shape[0] - (SHIFT_WIDTH//2):\n",
    "                same_c = 0\n",
    "                tmp1 = np.hstack((signal[cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)], feat1))\n",
    "                tmp1 = np.hstack((tmp1, feat2))\n",
    "                chopped_signals.append(tmp1)\n",
    "                chopped_labels.append(1)\n",
    "                count_1 += 1\n",
    "                    \n",
    "                for relative_x in range(-SHIFT_WIDTH//4 + cp, SHIFT_WIDTH//4 + cp, REG_JUMP):\n",
    "                    reg_signal_seq = signal[relative_x - (SHIFT_WIDTH//2): relative_x + (SHIFT_WIDTH//2)]\n",
    "                    if reg_signal_seq.shape[0] == SHIFT_WIDTH:\n",
    "                        reg_chopped_signals.append(reg_signal_seq)\n",
    "                        reg_chopped_labels.append(cp - relative_x)\n",
    "                    \n",
    "                while True:\n",
    "                    pat += 1\n",
    "                    random_selec = np.random.randint(0, T)\n",
    "                    random_selec_reg = set(np.arange(random_selec - SHIFT_WIDTH//4, random_selec + SHIFT_WIDTH//4))\n",
    "                        \n",
    "                    if len(changepoints_reg & random_selec_reg) == 0:\n",
    "                        if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[0] - (SHIFT_WIDTH//2):\n",
    "                            tmp0 = np.hstack((signal[random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)], feat1))\n",
    "                            tmp0 = np.hstack((tmp0, feat2))\n",
    "                            chopped_signals.append(tmp0)\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        elif random_selec < (SHIFT_WIDTH//2):\n",
    "                            tmp0 = np.hstack((signal[random_selec:random_selec + SHIFT_WIDTH], feat1))\n",
    "                            tmp0 = np.hstack((tmp0, feat2))\n",
    "                            chopped_signals.append(tmp0)\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        else:\n",
    "                            tmp0 = np.hstack((signal[random_selec - SHIFT_WIDTH:random_selec], feat1))\n",
    "                            tmp0 = np.hstack((tmp0, feat2))\n",
    "                            chopped_signals.append(tmp0)\n",
    "                            chopped_labels.append(0)\n",
    "                            \n",
    "                        count_0 += 1\n",
    "                        same_c += 1\n",
    "                        if same_c >= 3:\n",
    "                            break\n",
    "                    if pat >= 10:\n",
    "                        break\n",
    "    else:\n",
    "        for _ in range(1):\n",
    "            random_selec = np.random.randint(0, T)\n",
    "            if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[0] - (SHIFT_WIDTH//2):\n",
    "                tmp0 = np.hstack((signal[random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)], feat1))\n",
    "                tmp0 = np.hstack((tmp0, feat2))\n",
    "                chopped_signals.append(tmp0)\n",
    "                chopped_labels.append(0)\n",
    "            elif random_selec < (SHIFT_WIDTH//2):\n",
    "                tmp0 = np.hstack((signal[random_selec:random_selec + SHIFT_WIDTH], feat1))\n",
    "                tmp0 = np.hstack((tmp0, feat2))\n",
    "                chopped_signals.append(tmp0)\n",
    "                chopped_labels.append(0)\n",
    "            else:\n",
    "                tmp0 = np.hstack((signal[random_selec - SHIFT_WIDTH:random_selec], feat1))\n",
    "                tmp0 = np.hstack((tmp0, feat2))\n",
    "                chopped_signals.append(tmp0)\n",
    "                chopped_labels.append(0)\n",
    "            count_0 += 1\n",
    "    return np.array(chopped_signals), np.array(chopped_labels), count_0, count_1, np.array(reg_chopped_signals), np.array(reg_chopped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14bb7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "100 3738 2747\n",
      "200 7390 5525\n",
      "300 11214 8333\n",
      "400 14938 11220\n",
      "500 18685 14004\n",
      "600 22350 16711\n",
      "700 25983 19472\n",
      "800 29693 22276\n",
      "900 33426 25064\n",
      "1000 37291 27826\n",
      "1100 40946 30560\n",
      "1200 44621 33415\n",
      "1300 48461 36257\n",
      "1400 52214 39063\n"
     ]
    }
   ],
   "source": [
    "input_signals = []\n",
    "input_labels = []\n",
    "input_reg_signals = []\n",
    "input_reg_labels = []\n",
    "\n",
    "K_bound = [1e-12, 1000000.0]\n",
    "alpha_bound = [0, 1.999]\n",
    "alphas1 = [0.001, 0.3]\n",
    "alphas2 = [1.0, 1.999]\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for step in range(1500):\n",
    "    if step % 100 == 0: print(step, count_0, count_1)\n",
    "    alpha1 = np.random.uniform(alphas1[0], alphas1[1])\n",
    "    alpha2 = np.random.uniform(alphas2[0], alphas2[1])\n",
    "    single_alpha = np.random.choice([alpha1, alpha2])\n",
    "    multi_trajs_model, multi_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[alpha1, alpha2],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.05, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[0.98, 0.02], [0.02, 0.98]]\n",
    "                                                           )\n",
    "\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[single_alpha, single_alpha],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    \n",
    "    for i in range(N):\n",
    "        multi_s, multi_s_norm = make_signal(multi_trajs_model[:, i, 0], multi_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(multi_labels_model[:, i, :])\n",
    "        \n",
    "        comp_signal = compress_signals(multi_s)\n",
    "        feat1 = np.mean(comp_signal)**2 / np.std(comp_signal)**2\n",
    "        feat2 = np.max(multi_s, axis=1).mean()\n",
    "        \n",
    "        chop_signal, chop_label, count_0, count_1, reg_signal, reg_label = chop_with_shift(comp_signal,\n",
    "                                                                                           feat1,\n",
    "                                                                                           feat2,\n",
    "                                                                                           changepoints[:-1], \n",
    "                                                                                           count_0, count_1)        \n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "        input_reg_signals.extend(reg_signal)\n",
    "        input_reg_labels.extend(reg_label)\n",
    "\n",
    "        single_s, single_s_norm = make_signal(single_trajs_model[:, i, 0], single_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, i, :])\n",
    "        \n",
    "        comp_signal = compress_signals(single_s)\n",
    "        feat1 = np.mean(comp_signal)**2 / np.std(comp_signal)**2\n",
    "        feat2 = np.max(single_s, axis=1).mean()\n",
    "        \n",
    "        chop_signal, chop_label, count_0, count_1, _, _ = chop_with_shift(comp_signal,\n",
    "                                                                          feat1,\n",
    "                                                                          feat2,\n",
    "                                                                          changepoints[:-1],\n",
    "                                                                          count_0, count_1)        \n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "\n",
    "for i in range(1000):\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=2,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[1.0, 1.0],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    single_s, single_s_norm = make_signal(single_trajs_model[:, 0, 0], single_trajs_model[:, 0, 1], WINDOW_WIDTHS)\n",
    "    changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, 0, :])\n",
    "    \n",
    "    comp_signal = compress_signals(single_s)\n",
    "    feat1 = np.mean(comp_signal)**2 / np.std(comp_signal)**2\n",
    "    feat2 = np.max(single_s, axis=1).mean()\n",
    "    \n",
    "    chop_signal, chop_label, count_0, count_1, _, _ = chop_with_shift(comp_signal,\n",
    "                                                                      feat1,\n",
    "                                                                      feat2,\n",
    "                                                                      changepoints[:-1],\n",
    "                                                                      count_0,\n",
    "                                                                      count_1)        \n",
    "    input_signals.extend(chop_signal)\n",
    "    input_labels.extend(chop_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5f1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = np.array(input_signals)\n",
    "input_labels = np.array(input_labels)\n",
    "input_reg_signals = np.array(input_reg_signals)\n",
    "input_reg_labels = np.array(input_reg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2a0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98661, 62) (98661,)\n",
      "(595589, 60) (595589,)\n",
      "56847 41814\n",
      "[0.86777666 1.17976037]\n"
     ]
    }
   ],
   "source": [
    "total = count_0 + count_1\n",
    "weight_for_0 = (1 / count_0) * (total / 2.0)\n",
    "weight_for_1 = (1 / count_1) * (total / 2.0)\n",
    "class_weight = np.array([weight_for_0, weight_for_1])\n",
    "\n",
    "print(input_signals.shape, input_labels.shape)\n",
    "print(input_reg_signals.shape, input_reg_labels.shape)\n",
    "print(count_0, count_1)\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0db2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f'./training_set_{SHIFT_WIDTH}_{REG_JUMP}.npz',\n",
    "                    input_signals=input_signals,\n",
    "                    input_labels=input_labels,\n",
    "                    input_reg_signals=input_reg_signals,\n",
    "                    input_reg_labels=input_reg_labels,\n",
    "                    count_0=count_0,\n",
    "                    count_1=count_1,\n",
    "                    class_weight=class_weight,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e15e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
