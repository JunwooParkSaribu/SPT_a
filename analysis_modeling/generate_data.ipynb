{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21507f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "import numpy as np\n",
    "import random\n",
    "from andi_datasets.models_phenom import models_phenom\n",
    "from andi_datasets.datasets_phenom import datasets_phenom\n",
    "from andi_datasets.utils_challenge import label_continuous_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "T = 600\n",
    "L = None\n",
    "\n",
    "WINDOW_WIDTHS = np.arange(20, 100, 2)\n",
    "SHIFT_WIDTH = 40\n",
    "REG_JUMP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f88640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncumulate(xs:np.ndarray):\n",
    "    assert xs.ndim == 1\n",
    "    uncum_list = [0.]\n",
    "    for i in range(1, len(xs)):\n",
    "        uncum_list.append(xs[i] - xs[i-1])\n",
    "    return np.array(uncum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(x_pos, y_pos, win_widths):\n",
    "    all_vals = []\n",
    "    for win_width in win_widths:\n",
    "        if win_width >= len(x_pos):\n",
    "            continue\n",
    "        vals = []\n",
    "        for checkpoint in range(int(win_width/2), len(x_pos) - int(win_width/2)):\n",
    "            xs = x_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "            ys = y_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "\n",
    "            xs1 = xs[:int(len(xs)/2)] - float(xs[:int(len(xs)/2)][0])\n",
    "            xs2 = xs[int(len(xs)/2):] - float(xs[int(len(xs)/2):][0])\n",
    "\n",
    "            ys1 = ys[:int(len(ys)/2)] - float(ys[:int(len(ys)/2)][0])\n",
    "            ys2 = ys[int(len(ys)/2):] - float(ys[int(len(ys)/2):][0])\n",
    "\n",
    "            std_xs1 = np.std(xs1)\n",
    "            std_xs2 = np.std(xs2)\n",
    "            std_ys1 = np.std(ys1)\n",
    "            std_ys2 = np.std(ys2)\n",
    "\n",
    "            surface_xs1 = abs(np.sum(xs1)) / win_width\n",
    "            surface_xs2 = abs(np.sum(xs2)) / win_width\n",
    "            surface_ys1 = abs(np.sum(ys1)) / win_width\n",
    "            surface_ys2 = abs(np.sum(ys2)) / win_width\n",
    "\n",
    "\n",
    "            xs1 = np.cumsum(abs(xs1)) #* surface_xs1\n",
    "            xs2 = np.cumsum(abs(xs2)) #* surface_xs2\n",
    "            ys1 = np.cumsum(abs(ys1)) #* surface_ys1\n",
    "            ys2 = np.cumsum(abs(ys2)) #* surface_ys2\n",
    "\n",
    "\n",
    "            xs_max_val = max(np.max(abs(xs1)), np.max(abs(xs2)))\n",
    "            xs1 = xs1 / xs_max_val\n",
    "            xs2 = xs2 / xs_max_val\n",
    "            xs1 = xs1 / win_width\n",
    "            xs2 = xs2 / win_width\n",
    "\n",
    "            ys_max_val = max(np.max(abs(ys1)), np.max(abs(ys2)))\n",
    "            ys1 = ys1 / ys_max_val\n",
    "            ys2 = ys2 / ys_max_val\n",
    "            ys1 = ys1 / win_width \n",
    "            ys2 = ys2 / win_width\n",
    "\n",
    "            vals.append(abs(np.sum(xs1 - xs2 + ys1 - ys2)) \n",
    "                       * (max(std_xs1, std_xs2) / min(std_xs1, std_xs2)) \n",
    "                             * (max(std_ys1, std_ys2) / min(std_ys1, std_ys2)))\n",
    "\n",
    "        vals = np.concatenate((np.ones(int(win_width/2)) * 0, vals))\n",
    "        vals = np.concatenate((vals, np.ones(int(win_width/2)) * 0))\n",
    "        vals = np.array(vals)\n",
    "        all_vals.append(vals)\n",
    "    \n",
    "    all_vals = np.array(all_vals) + 1e-7\n",
    "    normalized_vals = all_vals.copy()\n",
    "    for i in range(len(normalized_vals)):\n",
    "            normalized_vals[i] = normalized_vals[i] / np.max(normalized_vals[i])\n",
    "    return all_vals, normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66326507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data(signal_seq, jump_d, ext_width, shift_width):\n",
    "    slice_d = []\n",
    "    indice = []\n",
    "    for i in range(ext_width, signal_seq.shape[1] - ext_width, jump_d):\n",
    "        crop = signal_seq[:, i - shift_width//2: i + shift_width//2]\n",
    "        if crop.shape[1] != shift_width:\n",
    "            crop = np.hstack((crop, np.zeros((crop.shape[0], shift_width - crop.shape[1])) ))\n",
    "        slice_d.append(crop)\n",
    "        indice.append(i)\n",
    "    return np.array(slice_d), np.array(indice) - ext_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56f1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_from_extended_data(x, y, win_widths, ext_width, shift_width):\n",
    "    datas = []\n",
    "    for data in [x, y]:\n",
    "        delta_prev_data = -uncumulate(data[:min(data.shape[0], ext_width)])\n",
    "        delta_prev_data[0] += float(data[0])\n",
    "        prev_data = np.cumsum(delta_prev_data)[::-1]\n",
    "\n",
    "        delta_next_data = -uncumulate(data[data.shape[0] - min(data.shape[0], ext_width):][::-1])\n",
    "        delta_next_data[0] += float(data[-1])\n",
    "        next_data = np.cumsum(delta_next_data)\n",
    "\n",
    "        ext_data = np.concatenate((prev_data, data))\n",
    "        ext_data = np.concatenate((ext_data, next_data))\n",
    "        datas.append(ext_data)\n",
    "\n",
    "    signal, norm_signal = make_signal(datas[0], datas[1], win_widths)\n",
    "    sliced_signals, slice_indice = slice_data(signal, 1, min(data.shape[0], ext_width), 10)\n",
    "\n",
    "    return (signal[:, delta_prev_data.shape[0]:signal.shape[1] - delta_next_data.shape[0]],\n",
    "            norm_signal[:, delta_prev_data.shape[0]:signal.shape[1] - delta_next_data.shape[0]],\n",
    "           sliced_signals,\n",
    "           slice_indice,\n",
    "           signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847a01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_with_shift(signal, norm_signal, slice_sum_norm, changepoints=None, count_0=None, count_1=None):\n",
    "    chopped_signals = []\n",
    "    chopped_labels = []\n",
    "    reg_chopped_signals = []\n",
    "    reg_chopped_labels = []\n",
    "    chopped_slice_sum = []\n",
    "    pat=0\n",
    "\n",
    "    changepoints_reg = []\n",
    "    for cp in changepoints:\n",
    "        changepoints_reg.extend(range(cp - SHIFT_WIDTH//4, cp + SHIFT_WIDTH//4))\n",
    "    changepoints_reg = set(changepoints_reg)\n",
    "        \n",
    "    if len(changepoints) != 0:\n",
    "        for cp in changepoints:\n",
    "            if cp >= (SHIFT_WIDTH//2) and cp < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                same_c = 0\n",
    "                chopped_signals.append(np.hstack((signal[:, cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)],\n",
    "                                                  norm_signal[:, cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)])))\n",
    "                chopped_slice_sum.append(slice_sum_norm[cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)])\n",
    "                chopped_labels.append(1)\n",
    "                count_1 += 1\n",
    "                for relative_x in range(-REG_JUMP*3 + cp, REG_JUMP*3 + cp, REG_JUMP):\n",
    "                    reg_signal_seq = signal[:, relative_x - (SHIFT_WIDTH//2): relative_x + (SHIFT_WIDTH//2)]\n",
    "                    norm_reg_signal_seq = norm_signal[:, relative_x - (SHIFT_WIDTH//2): relative_x + (SHIFT_WIDTH//2)]\n",
    "                    if reg_signal_seq.shape[1] == SHIFT_WIDTH:\n",
    "                        reg_chopped_signals.append(np.hstack((reg_signal_seq, norm_reg_signal_seq)))\n",
    "                        reg_chopped_labels.append(cp - relative_x)\n",
    "                    \n",
    "                while True:\n",
    "                    pat += 1\n",
    "                    random_selec = np.random.randint(0, T)\n",
    "                    random_selec_reg = set(np.arange(random_selec - SHIFT_WIDTH//4, random_selec + SHIFT_WIDTH//4))\n",
    "                        \n",
    "                    if len(changepoints_reg & random_selec_reg) == 0:\n",
    "                        if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)],\n",
    "                                                             norm_signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])))\n",
    "                            chopped_slice_sum.append(slice_sum_norm[random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        elif random_selec < (SHIFT_WIDTH//2):\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec:random_selec + SHIFT_WIDTH],\n",
    "                                                             norm_signal[:, random_selec:random_selec + SHIFT_WIDTH])))\n",
    "                            chopped_slice_sum.append(slice_sum_norm[random_selec:random_selec + SHIFT_WIDTH])\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        else:\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec - SHIFT_WIDTH:random_selec],\n",
    "                                                             norm_signal[:, random_selec - SHIFT_WIDTH:random_selec])))\n",
    "                            chopped_slice_sum.append(slice_sum_norm[random_selec - SHIFT_WIDTH:random_selec])\n",
    "                            chopped_labels.append(0)\n",
    "                        count_0 += 1\n",
    "                        same_c += 1\n",
    "                        if same_c >= 3:\n",
    "                            break\n",
    "                    if pat >= 20:\n",
    "                        break\n",
    "    else:\n",
    "        for _ in range(1):\n",
    "            random_selec = np.random.randint(0, T)\n",
    "            if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)],\n",
    "                                                norm_signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])))\n",
    "                chopped_slice_sum.append(slice_sum_norm[random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])\n",
    "                chopped_labels.append(0)\n",
    "            elif random_selec < (SHIFT_WIDTH//2):\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec:random_selec + SHIFT_WIDTH],\n",
    "                                                 norm_signal[:, random_selec:random_selec + SHIFT_WIDTH])))\n",
    "                chopped_slice_sum.append(slice_sum_norm[random_selec:random_selec + SHIFT_WIDTH])\n",
    "                chopped_labels.append(0)\n",
    "            else:\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec - SHIFT_WIDTH:random_selec],\n",
    "                                                 norm_signal[:, random_selec - SHIFT_WIDTH:random_selec])))\n",
    "                chopped_slice_sum.append(slice_sum_norm[random_selec - SHIFT_WIDTH:random_selec])              \n",
    "                chopped_labels.append(0)\n",
    "            count_0 += 1\n",
    "    return (np.array(chopped_signals), np.array(chopped_labels), \n",
    "            count_0, count_1, \n",
    "            np.array(reg_chopped_signals), np.array(reg_chopped_labels),\n",
    "            np.array(chopped_slice_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 | 100 2666 1121 | 200 5273 2229 | 300 7937 3358 | 400 10587 4482 | 500 13182 5607 | 600 15755 6723 | 700 18388 7812 | "
     ]
    }
   ],
   "source": [
    "input_signals = []\n",
    "input_labels = []\n",
    "input_reg_signals = []\n",
    "input_reg_labels = []\n",
    "input_features = []\n",
    "input_slice_sum = []\n",
    "input_slice_snr = []\n",
    "\n",
    "K_bound = [1e-12, 1000000.0]\n",
    "alpha_bound = [0, 1.999]\n",
    "alphas1 = [0.01, 0.4]\n",
    "alphas2 = [0.65, 1.9]\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for step in range(3000):\n",
    "    if step % 100 == 0: print(step, count_0, count_1, end=' | ')\n",
    "    alpha1 = np.random.uniform(alphas1[0], alphas1[1])\n",
    "    alpha2 = np.random.uniform(alphas2[0], alphas2[1])\n",
    "    single_alpha = np.random.choice([alpha1, alpha2])\n",
    "    multi_trajs_model, multi_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[alpha1, alpha2],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.04, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[0.99, 0.01], [0.01, 0.99]]\n",
    "                                                           )\n",
    "\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[single_alpha, single_alpha],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    \n",
    "    for i in range(N):\n",
    "        multi_s, multi_s_norm, multi_sliced_signals, _, _ = signal_from_extended_data(multi_trajs_model[:, i, 0],\n",
    "                                                                                      multi_trajs_model[:, i, 1],\n",
    "                                                                                      WINDOW_WIDTHS,\n",
    "                                                                                      WINDOW_WIDTHS[-1]//2,\n",
    "                                                                                      SHIFT_WIDTH)\n",
    "\n",
    "        slice_sum = np.sum(multi_sliced_signals, axis=(1, 2))\n",
    "        slice_sum /= np.max(slice_sum)\n",
    "        slice_sum_SNR = np.mean(slice_sum)**2 / np.std(slice_sum)**2\n",
    "        \n",
    "        #multi_s, multi_s_norm = make_signal(multi_trajs_model[:, i, 0], multi_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(multi_labels_model[:, i, :])\n",
    "        chop_signal, chop_label, count_0, count_1, reg_signal, reg_label, chop_slice_sum = chop_with_shift(multi_s,\n",
    "                                                                                           multi_s_norm,\n",
    "                                                                                           slice_sum,\n",
    "                                                                                           changepoints[:-1], \n",
    "                                                                                           count_0, count_1)\n",
    "        \n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "        input_reg_signals.extend(reg_signal)\n",
    "        input_reg_labels.extend(reg_label)\n",
    "        \n",
    "        input_slice_sum.extend(chop_slice_sum)\n",
    "        input_slice_snr.extend([slice_sum_SNR] * len(chop_slice_sum))\n",
    "        \n",
    "        feat1 = np.array([np.mean(multi_s, axis=1)**2 / np.std(multi_s, axis=1)**2] * chop_signal.shape[0])\n",
    "        input_features.extend(feat1)\n",
    "        \n",
    "        single_s, single_s_norm, single_sliced_singals, _, _ = signal_from_extended_data(single_trajs_model[:, i, 0],\n",
    "                                                                                         single_trajs_model[:, i, 1],\n",
    "                                                                                         WINDOW_WIDTHS,\n",
    "                                                                                         WINDOW_WIDTHS[-1]//2,\n",
    "                                                                                         SHIFT_WIDTH)\n",
    "        \n",
    "        slice_sum = np.sum(single_sliced_singals, axis=(1, 2))\n",
    "        slice_sum /= np.max(slice_sum)\n",
    "        slice_sum_SNR = np.mean(slice_sum)**2 / np.std(slice_sum)**2\n",
    "        \n",
    "        #single_s, single_s_norm = make_signal(single_trajs_model[:, i, 0], single_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, i, :])    \n",
    "        chop_signal, chop_label, count_0, count_1, _, _, chop_slice_sum = chop_with_shift(single_s,\n",
    "                                                                                          single_s_norm,\n",
    "                                                                                          slice_sum,\n",
    "                                                                                          changepoints[:-1],\n",
    "                                                                                          count_0, count_1)\n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "        \n",
    "        input_slice_sum.extend(chop_slice_sum)\n",
    "        input_slice_snr.extend([slice_sum_SNR] * len(chop_slice_sum))\n",
    "                \n",
    "        feat1 = np.array([np.mean(single_s, axis=1)**2 / np.std(single_s, axis=1)**2] * chop_signal.shape[0])\n",
    "        input_features.extend(feat1)\n",
    "        \n",
    "\n",
    "for i in range(10000):\n",
    "    s_alphas = [0.5, 1.5]\n",
    "    s_alpha = np.random.uniform(s_alphas[0], s_alphas[1])\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=2,\n",
    "                                                            L=L,\n",
    "                                                            T=200,\n",
    "                                                            alphas=[s_alpha, s_alpha],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.01], [0.1, 0.01]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    \n",
    "    single_s, single_s_norm, single_sliced_singals, _, _ = signal_from_extended_data(single_trajs_model[:, 0, 0],\n",
    "                                                                                     single_trajs_model[:, 0, 1],\n",
    "                                                                                     WINDOW_WIDTHS,\n",
    "                                                                                     WINDOW_WIDTHS[-1]//2,\n",
    "                                                                                     SHIFT_WIDTH)\n",
    "    \n",
    "    slice_sum = np.sum(single_sliced_singals, axis=(1, 2))\n",
    "    slice_sum /= np.max(slice_sum)\n",
    "    slice_sum_SNR = np.mean(slice_sum)**2 / np.std(slice_sum)**2\n",
    "    \n",
    "    #single_s, single_s_norm = make_signal(single_trajs_model[:, 0, 0], single_trajs_model[:, 0, 1], WINDOW_WIDTHS)\n",
    "    changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, 0, :])\n",
    "    chop_signal, chop_label, count_0, count_1, _, _, chop_slice_sum = chop_with_shift(single_s,\n",
    "                                                                                      single_s_norm,\n",
    "                                                                                      slice_sum,\n",
    "                                                                                      changepoints[:-1],\n",
    "                                                                                      count_0, count_1)        \n",
    "    input_signals.extend(chop_signal)\n",
    "    input_labels.extend(chop_label)\n",
    "    \n",
    "    input_slice_sum.extend(chop_slice_sum)\n",
    "    input_slice_snr.extend([slice_sum_SNR] * len(chop_slice_sum))\n",
    "    \n",
    "    feat1 = np.array([np.mean(single_s, axis=1)**2 / np.std(single_s, axis=1)**2] * chop_signal.shape[0])\n",
    "    input_features.extend(feat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = np.array(input_signals)\n",
    "input_labels = np.array(input_labels)\n",
    "input_reg_signals = np.array(input_reg_signals)\n",
    "input_reg_labels = np.array(input_reg_labels)\n",
    "input_features = np.array(input_features)\n",
    "input_slice_sum = np.array(input_slice_sum)\n",
    "input_slice_snr = np.array(input_slice_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_signals.shape, input_labels.shape)\n",
    "print(input_reg_signals.shape, input_reg_labels.shape)\n",
    "print(input_features.shape)\n",
    "print(input_slice_sum.shape, input_slice_snr.shape)\n",
    "print(count_0, count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0db2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f'./training_set_{SHIFT_WIDTH}_{REG_JUMP}.npz',\n",
    "                    input_signals=input_signals,\n",
    "                    input_labels=input_labels,\n",
    "                    input_reg_signals=input_reg_signals,\n",
    "                    input_reg_labels=input_reg_labels,\n",
    "                    count_0=count_0,\n",
    "                    count_1=count_1,\n",
    "                    input_features=input_features,\n",
    "                    input_slice_sum=input_slice_sum,\n",
    "                    input_slice_snr=input_slice_snr\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e15e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
