{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21507f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "import numpy as np\n",
    "import random\n",
    "from andi_datasets.models_phenom import models_phenom\n",
    "from andi_datasets.datasets_phenom import datasets_phenom\n",
    "from andi_datasets.utils_challenge import label_continuous_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5269d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "T = 200\n",
    "L = None\n",
    "\n",
    "WINDOW_WIDTHS = np.arange(6, 100, 2)\n",
    "SHIFT_WIDTH = 60\n",
    "REG_JUMP = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f88640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncumulate(xs:np.ndarray):\n",
    "    assert xs.ndim == 1\n",
    "    uncum_list = [0.]\n",
    "    for i in range(1, len(xs)):\n",
    "        uncum_list.append(xs[i] - xs[i-1])\n",
    "    return np.array(uncum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_signal(x_pos, y_pos, win_widths):\n",
    "    all_vals = []\n",
    "    for win_width in win_widths:\n",
    "        if win_width >= len(x_pos):\n",
    "            continue\n",
    "        vals = []\n",
    "        for checkpoint in range(int(win_width/2), len(x_pos) - int(win_width/2)):\n",
    "            xs = x_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "            ys = y_pos[checkpoint - int(win_width/2) : checkpoint + int(win_width/2)]\n",
    "\n",
    "            xs1 = xs[:int(len(xs)/2)] - float(xs[:int(len(xs)/2)][0])\n",
    "            xs2 = xs[int(len(xs)/2):] - float(xs[int(len(xs)/2):][0])\n",
    "\n",
    "            ys1 = ys[:int(len(ys)/2)] - float(ys[:int(len(ys)/2)][0])\n",
    "            ys2 = ys[int(len(ys)/2):] - float(ys[int(len(ys)/2):][0])\n",
    "\n",
    "            std_xs1 = np.std(xs1)\n",
    "            std_xs2 = np.std(xs2)\n",
    "            std_ys1 = np.std(ys1)\n",
    "            std_ys2 = np.std(ys2)\n",
    "\n",
    "            surface_xs1 = abs(np.sum(xs1)) / win_width\n",
    "            surface_xs2 = abs(np.sum(xs2)) / win_width\n",
    "            surface_ys1 = abs(np.sum(ys1)) / win_width\n",
    "            surface_ys2 = abs(np.sum(ys2)) / win_width\n",
    "\n",
    "\n",
    "            xs1 = np.cumsum(abs(xs1)) #* surface_xs1\n",
    "            xs2 = np.cumsum(abs(xs2)) #* surface_xs2\n",
    "            ys1 = np.cumsum(abs(ys1)) #* surface_ys1\n",
    "            ys2 = np.cumsum(abs(ys2)) #* surface_ys2\n",
    "\n",
    "\n",
    "            xs_max_val = max(np.max(abs(xs1)), np.max(abs(xs2)))\n",
    "            xs1 = xs1 / xs_max_val\n",
    "            xs2 = xs2 / xs_max_val\n",
    "            xs1 = xs1 / win_width\n",
    "            xs2 = xs2 / win_width\n",
    "\n",
    "            ys_max_val = max(np.max(abs(ys1)), np.max(abs(ys2)))\n",
    "            ys1 = ys1 / ys_max_val\n",
    "            ys2 = ys2 / ys_max_val\n",
    "            ys1 = ys1 / win_width \n",
    "            ys2 = ys2 / win_width\n",
    "\n",
    "            vals.append(abs(np.sum(xs1 - xs2 + ys1 - ys2)) \n",
    "                       * (max(std_xs1, std_xs2) / min(std_xs1, std_xs2)) \n",
    "                             * (max(std_ys1, std_ys2) / min(std_ys1, std_ys2)))\n",
    "\n",
    "        vals = np.concatenate((np.ones(int(win_width/2)) * -1, vals))\n",
    "        vals = np.concatenate((vals, np.ones(int(win_width/2)) * -1))\n",
    "        vals = np.array(vals)\n",
    "        all_vals.append(vals)\n",
    "    \n",
    "    all_vals = np.array(all_vals) + 1e-7\n",
    "    normalized_vals = all_vals.copy()\n",
    "    for i in range(len(normalized_vals)):\n",
    "            normalized_vals[i] = normalized_vals[i] / np.max(normalized_vals[i])\n",
    "    return all_vals, normalized_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847a01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_with_shift(signal, norm_signal, changepoints=None, count_0=None, count_1=None):\n",
    "    chopped_signals = []\n",
    "    chopped_labels = []\n",
    "    reg_chopped_signals = []\n",
    "    reg_chopped_labels = []\n",
    "    pat=0\n",
    "\n",
    "    changepoints_reg = []\n",
    "    for cp in changepoints:\n",
    "        changepoints_reg.extend(range(cp - SHIFT_WIDTH//4, cp + SHIFT_WIDTH//4))\n",
    "    changepoints_reg = set(changepoints_reg)\n",
    "        \n",
    "    if len(changepoints) != 0:\n",
    "        for cp in changepoints:\n",
    "            if cp >= (SHIFT_WIDTH//2) and cp < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                same_c = 0\n",
    "                chopped_signals.append(np.hstack((signal[:, cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)],\n",
    "                                                  norm_signal[:, cp - (SHIFT_WIDTH//2):cp + (SHIFT_WIDTH//2)])))\n",
    "                chopped_labels.append(1)\n",
    "                count_1 += 1\n",
    "                for relative_x in range(-SHIFT_WIDTH//4 + cp, SHIFT_WIDTH//4 + cp, REG_JUMP):\n",
    "                    reg_signal_seq = signal[:, relative_x - (SHIFT_WIDTH//2): relative_x + (SHIFT_WIDTH//2)]\n",
    "                    norm_reg_signal_seq = norm_signal[:, relative_x - (SHIFT_WIDTH//2): relative_x + (SHIFT_WIDTH//2)]\n",
    "                    if reg_signal_seq.shape[1] == SHIFT_WIDTH:\n",
    "                        reg_chopped_signals.append(np.hstack((reg_signal_seq, norm_reg_signal_seq)))\n",
    "                        reg_chopped_labels.append(cp - relative_x)\n",
    "                    \n",
    "                while True:\n",
    "                    pat += 1\n",
    "                    random_selec = np.random.randint(0, T)\n",
    "                    random_selec_reg = set(np.arange(random_selec - SHIFT_WIDTH//4, random_selec + SHIFT_WIDTH//4))\n",
    "                        \n",
    "                    if len(changepoints_reg & random_selec_reg) == 0:\n",
    "                        if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)],\n",
    "                                                             norm_signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])))\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        elif random_selec < (SHIFT_WIDTH//2):\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec:random_selec + SHIFT_WIDTH],\n",
    "                                                             norm_signal[:, random_selec:random_selec + SHIFT_WIDTH])))\n",
    "                            chopped_labels.append(0)\n",
    "\n",
    "                        else:\n",
    "                            chopped_signals.append(np.hstack((signal[:, random_selec - SHIFT_WIDTH:random_selec],\n",
    "                                                             norm_signal[:, random_selec - SHIFT_WIDTH:random_selec])))\n",
    "                            chopped_labels.append(0)\n",
    "                        count_0 += 1\n",
    "                        same_c += 1\n",
    "                        if same_c >= 3:\n",
    "                            break\n",
    "                    if pat >= 10:\n",
    "                        break\n",
    "    else:\n",
    "        for _ in range(1):\n",
    "            random_selec = np.random.randint(0, T)\n",
    "            if random_selec >= (SHIFT_WIDTH//2) and random_selec < signal.shape[1] - (SHIFT_WIDTH//2):\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)],\n",
    "                                                norm_signal[:, random_selec - (SHIFT_WIDTH//2):random_selec + (SHIFT_WIDTH//2)])))\n",
    "                chopped_labels.append(0)\n",
    "            elif random_selec < (SHIFT_WIDTH//2):\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec:random_selec + SHIFT_WIDTH],\n",
    "                                                 norm_signal[:, random_selec:random_selec + SHIFT_WIDTH])))\n",
    "                chopped_labels.append(0)\n",
    "            else:\n",
    "                chopped_signals.append(np.hstack((signal[:, random_selec - SHIFT_WIDTH:random_selec],\n",
    "                                                 norm_signal[:, random_selec - SHIFT_WIDTH:random_selec])))\n",
    "                chopped_labels.append(0)\n",
    "            count_0 += 1\n",
    "    return np.array(chopped_signals), np.array(chopped_labels), count_0, count_1, np.array(reg_chopped_signals), np.array(reg_chopped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 | 100 3664 2769 | 200 7439 5549 | 300 11121 8390 | 400 14841 11220 | 500 18569 13980 | 600 22543 16764 | 700 26212 19593 | 800 29984 22391 | 900 33787 25172 | 1000 37554 27939 | 1100 41354 30651 | 1200 45015 33401 | 1300 48672 36101 | "
     ]
    }
   ],
   "source": [
    "input_signals = []\n",
    "input_labels = []\n",
    "input_reg_signals = []\n",
    "input_reg_labels = []\n",
    "input_features = []\n",
    "\n",
    "K_bound = [1e-12, 1000000.0]\n",
    "alpha_bound = [0, 1.999]\n",
    "alphas1 = [0.001, 0.25]\n",
    "alphas2 = [1.1, 1.999]\n",
    "count_0 = 0\n",
    "count_1 = 0\n",
    "\n",
    "for step in range(1500):\n",
    "    if step % 100 == 0: print(step, count_0, count_1, end=' | ')\n",
    "    alpha1 = np.random.uniform(alphas1[0], alphas1[1])\n",
    "    alpha2 = np.random.uniform(alphas2[0], alphas2[1])\n",
    "    single_alpha = np.random.choice([alpha1, alpha2])\n",
    "    multi_trajs_model, multi_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[alpha1, alpha2],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.025, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[0.98, 0.02], [0.02, 0.98]]\n",
    "                                                           )\n",
    "\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=N,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[single_alpha, single_alpha],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.0], [0.1, 0.0]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    \n",
    "    for i in range(N):\n",
    "        multi_s, multi_s_norm = make_signal(multi_trajs_model[:, i, 0], multi_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(multi_labels_model[:, i, :])\n",
    "        chop_signal, chop_label, count_0, count_1, reg_signal, reg_label = chop_with_shift(multi_s,\n",
    "                                                                                           multi_s_norm,\n",
    "                                                                                           changepoints[:-1], \n",
    "                                                                                           count_0, count_1)\n",
    "        \n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "        input_reg_signals.extend(reg_signal)\n",
    "        input_reg_labels.extend(reg_label)\n",
    "                \n",
    "        feat1 = np.array([np.mean(multi_s_norm, axis=1)**2 / np.std(multi_s_norm)**2] * chop_signal.shape[0])\n",
    "        input_features.extend(feat1)\n",
    "        \n",
    "        single_s, single_s_norm = make_signal(single_trajs_model[:, i, 0], single_trajs_model[:, i, 1], WINDOW_WIDTHS)\n",
    "        changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, i, :])\n",
    "        \n",
    "        chop_signal, chop_label, count_0, count_1, _, _ = chop_with_shift(single_s,\n",
    "                                                                          single_s_norm,\n",
    "                                                                          changepoints[:-1],\n",
    "                                                                          count_0, count_1)\n",
    "        input_signals.extend(chop_signal)\n",
    "        input_labels.extend(chop_label)\n",
    "                \n",
    "        feat1 = np.array([np.mean(single_s_norm, axis=1)**2 / np.std(single_s_norm)**2] * chop_signal.shape[0])\n",
    "        input_features.extend(feat1)\n",
    "\n",
    "for i in range(1000):\n",
    "    s_alphas = [0.8, 1.2]\n",
    "    s_alpha = np.random.uniform(s_alphas[0], s_alphas[1])\n",
    "    single_trajs_model, single_labels_model = models_phenom().multi_state(N=2,\n",
    "                                                            L=L,\n",
    "                                                            T=T,\n",
    "                                                            alphas=[s_alpha, s_alpha],  # Fixed alpha for each state\n",
    "                                                            Ds=[[0.1, 0.01], [0.1, 0.01]],# Mean and variance of each state\n",
    "                                                            M=[[1.0, 0.0], [0.0, 1.0]]\n",
    "                                                           )\n",
    "    single_s, single_s_norm = make_signal(single_trajs_model[:, 0, 0], single_trajs_model[:, 0, 1], WINDOW_WIDTHS)\n",
    "    changepoints, alphas_cp, Ds, state_num = label_continuous_to_list(single_labels_model[:, 0, :])\n",
    "    \n",
    "    chop_signal, chop_label, count_0, count_1, _, _ = chop_with_shift(single_s,\n",
    "                                                                      single_s_norm,\n",
    "                                                                      changepoints[:-1],\n",
    "                                                                      count_0,\n",
    "                                                                      count_1)        \n",
    "    input_signals.extend(chop_signal)\n",
    "    input_labels.extend(chop_label)\n",
    "    \n",
    "    feat1 = np.array([np.mean(single_s_norm, axis=1)**2 / np.std(single_s_norm)**2] * chop_signal.shape[0])\n",
    "    input_features.extend(feat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5f1666",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_signals \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(input_signals)\n\u001b[1;32m      2\u001b[0m input_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(input_labels)\n\u001b[1;32m      3\u001b[0m input_reg_signals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(input_reg_signals)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "input_signals = np.array(input_signals)\n",
    "input_labels = np.array(input_labels)\n",
    "input_reg_signals = np.array(input_reg_signals)\n",
    "input_reg_labels = np.array(input_reg_labels)\n",
    "input_features = np.array(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a0f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_signals.shape, input_labels.shape)\n",
    "print(input_reg_signals.shape, input_reg_labels.shape)\n",
    "print(input_features.shape)\n",
    "print(count_0, count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0db2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f'./training_set_{SHIFT_WIDTH}_{REG_JUMP}.npz',\n",
    "                    input_signals=input_signals,\n",
    "                    input_labels=input_labels,\n",
    "                    input_reg_signals=input_reg_signals,\n",
    "                    input_reg_labels=input_reg_labels,\n",
    "                    count_0=count_0,\n",
    "                    count_1=count_1,\n",
    "                    input_features=input_features\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e15e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
